{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartinNde/MartinN_1/blob/main/Image_Challenge_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3M2Gsa3A4va"
      },
      "source": [
        "#Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pVmRnjCAw7H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "from skimage.feature import hog\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# libraries for data plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# library for evaluation\n",
        "from sklearn import metrics\n",
        "\n",
        "# libraries for ML algorithms\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from random import randint\n",
        "from random import seed\n",
        "\n",
        "!pip install tensorflow tensorflow-gpu opencv-python matplotlib\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "gpus =tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu,True)\n",
        "\n",
        "RANDOM_SEED = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQNS-6BvA-YV"
      },
      "source": [
        "#Load image data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khaT7Iri_6RH"
      },
      "outputs": [],
      "source": [
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "srNOdMREBFsW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # unzip file\n",
        "import shutil\n",
        "# shutil.unpack_archive('/content/drive/MyDrive/data (2).zip', '/content/drive/MyDrive/Colab No\n",
        "shutil.unpack_archive('/content/drive/MyDrive/data (2).zip', '/content/drive/MyDrive/data', 'zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SX9_dGRdAjTQ"
      },
      "outputs": [],
      "source": [
        "data_folder = '/content/drive/MyDrive/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "QIvm-pRtqrE0",
        "outputId": "764d36f8-8338-4227-9395-3d166a79bd68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id label\n",
              "0   1   cat\n",
              "1   2   dog\n",
              "2   3   cat\n",
              "3   4   cat\n",
              "4   5   cat"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6cae7f3e-1ee7-4ce4-95f6-135b522f283b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cae7f3e-1ee7-4ce4-95f6-135b522f283b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cae7f3e-1ee7-4ce4-95f6-135b522f283b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cae7f3e-1ee7-4ce4-95f6-135b522f283b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "# load training data\n",
        "df_train = pd.read_csv(os.path.join(data_folder, 'train.csv'))\n",
        "\n",
        "# summarise the details\n",
        "print(f'Number of entries: {len(df_train)}')\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "W3Ud6IsGA20k",
        "outputId": "6b1e6585-778b-4107-b244-affd8f347bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id\n",
              "0   1\n",
              "1   2\n",
              "2   3\n",
              "3   4\n",
              "4   5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdfc1def-aba8-484b-b7cd-b9619556b0ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdfc1def-aba8-484b-b7cd-b9619556b0ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdfc1def-aba8-484b-b7cd-b9619556b0ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdfc1def-aba8-484b-b7cd-b9619556b0ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# load testing data\n",
        "df_test = pd.read_csv(os.path.join(data_folder, 'test.csv'))\n",
        "\n",
        "# summarise the details\n",
        "print(f'Number of entries: {len(df_test)}')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vKWrBYObA380",
        "outputId": "4d0ff067-8a7c-4d08-899d-a28878fb41de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAARWElEQVR4nO3df7CmZV3H8fdHVtISZZHTRrvQMrVToRbJhmTZKEyApi456GApG1FrE5U2/cKaCUNpdLJMLS2K1cUsQIwgx4k2VMxGfiy/BSQ2lGAH3ZVdUHK00G9/PNfRx2UP1yHO/Txn97xfM8+c+/5e13M/3zNzZj97/3xSVUiS9GieMO0GJEmLn2EhSeoyLCRJXYaFJKnLsJAkdS2bdgNDOPjgg2v16tXTbkOS9irXXXfdF6pqZk9j+2RYrF69mi1btky7DUnaqyS5e64xD0NJkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdQ0aFkk+m+SWJDcm2dJqByXZnOTO9nN5qyfJO5JsTXJzkmePbWd9m39nkvVD9ixJeqRJ7Fm8oKqOrKq1bf1M4IqqWgNc0dYBXgisaa8NwLthFC7AWcBzgKOBs2YDRpI0GdM4DLUO2NSWNwEnjdXPr5GrgAOTHAKcAGyuqp1VtQvYDJw44Z4laUkb+g7uAv4lSQF/VVXnAiuq6r42/jlgRVteCdwz9t57W22u+rdIsoHRHgmHHXbYQv4O0qLyX2c/a9otaBE67A9uGXT7Q4fFT1TVtiTfCWxO8unxwaqqFiSPWwuicwHWrl37uLd51G+f/7h70r7nuj8+ddotSFMx6GGoqtrWfm4HLmF0zuHz7fAS7ef2Nn0bcOjY21e12lx1SdKEDBYWSb4jyQGzy8DxwKeAy4DZK5rWA5e25cuAU9tVUccAD7bDVZcDxydZ3k5sH99qkqQJGfIw1ArgkiSzn/N3VfXPSa4FLkpyOnA38Io2/8PAi4CtwJeB0wCqameSNwLXtnlnV9XOAfuWJO1msLCoqruAH95D/X7guD3UCzhjjm1tBDYudI+SpPnxDm5JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugYPiyT7JbkhyYfa+uFJrk6yNcmFSfZv9W9r61vb+Oqxbby+1e9IcsLQPUuSvtUk9ixeC9w+tv4W4G1V9X3ALuD0Vj8d2NXqb2vzSHIEcArwDOBE4F1J9ptA35KkZtCwSLIK+Gngb9p6gGOBi9uUTcBJbXldW6eNH9fmrwMuqKqvVtVngK3A0UP2LUn6VkPvWfwZ8DvA19v604EHqurhtn4vsLItrwTuAWjjD7b536jv4T3fkGRDki1JtuzYsWOBfw1JWtoGC4skLwa2V9V1Q33GuKo6t6rWVtXamZmZSXykJC0Zywbc9o8DL03yIuBJwFOBtwMHJlnW9h5WAdva/G3AocC9SZYBTwPuH6vPGn+PJGkCBtuzqKrXV9WqqlrN6AT1R6rq54CPAie3aeuBS9vyZW2dNv6RqqpWP6VdLXU4sAa4Zqi+JUmPNOSexVx+F7ggyZuAG4DzWv084H1JtgI7GQUMVXVrkouA24CHgTOq6muTb1uSlq6JhEVVfQz4WFu+iz1czVRVXwFePsf7zwHOGa5DSdKj8Q5uSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lS12BhkeRJSa5JclOSW5P8YasfnuTqJFuTXJhk/1b/tra+tY2vHtvW61v9jiQnDNWzJGnPhtyz+CpwbFX9MHAkcGKSY4C3AG+rqu8DdgGnt/mnA7ta/W1tHkmOAE4BngGcCLwryX4D9i1J2s1gYVEjD7XVJ7ZXAccCF7f6JuCktryurdPGj0uSVr+gqr5aVZ8BtgJHD9W3JOmRBj1nkWS/JDcC24HNwH8CD1TVw23KvcDKtrwSuAegjT8IPH28vof3jH/WhiRbkmzZsWPHAL+NJC1dg4ZFVX2tqo4EVjHaG/iBAT/r3KpaW1VrZ2ZmhvoYSVqSJnI1VFU9AHwU+DHgwCTL2tAqYFtb3gYcCtDGnwbcP17fw3skSRMw5NVQM0kObMtPBn4KuJ1RaJzcpq0HLm3Ll7V12vhHqqpa/ZR2tdThwBrgmqH6liQ90rL+FEhyRVUd16vt5hBgU7ty6QnARVX1oSS3ARckeRNwA3Bem38e8L4kW4GdjK6AoqpuTXIRcBvwMHBGVX1t/r+iJOnxetSwSPIk4NuBg5MsB9KGnsoeTjKPq6qbgR/ZQ/0u9nA1U1V9BXj5HNs6Bzjn0T5PkjSc3p7Fa4DXAd8NXMc3w+KLwJ8P15YkaTF51LCoqrcDb0/ya1X1zgn1JElaZOZ1zqKq3pnkucDq8fdU1fkD9SVJWkTme4L7fcD3AjcCsyeXCzAsJGkJmFdYAGuBI9qlrJKkJWa+91l8CviuIRuRJC1e892zOBi4Lck1jJ4mC0BVvXSQriRJi8p8w+INQzYhSVrc5ns11JVDNyJJWrzmezXUlxhd/QSwP6PvpvjvqnrqUI1JkhaP+e5ZHDC7PPaFRMcM1ZQkaXF5zE+dbd+A94+A34UtSUvEfA9DvWxs9QmM7rv4yiAdSZIWnfleDfWSseWHgc8yOhQlSVoC5nvO4rShG5EkLV7zOmeRZFWSS5Jsb68PJlk1dHOSpMVhvie438Po602/u73+qdUkSUvAfMNipqreU1UPt9d7gZkB+5IkLSLzDYv7k7wqyX7t9Srg/iEbkyQtHvMNi18AXgF8DrgPOBn4+YF6kiQtMvO9dPZsYH1V7QJIchDwVkYhIknax813z+KHZoMCoKp2Aj8yTEuSpMVmvmHxhCTLZ1fansV890okSXu5+f6D/yfAJ5N8oK2/HDhnmJYkSYvNfO/gPj/JFuDYVnpZVd02XFuSpMVk3oeSWjgYEJK0BD3mR5RLkpYew0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2DhUWSQ5N8NMltSW5N8tpWPyjJ5iR3tp/LWz1J3pFka5Kbkzx7bFvr2/w7k6wfqmdJ0p4NuWfxMPCbVXUEcAxwRpIjgDOBK6pqDXBFWwd4IbCmvTYA74ZvPFrkLOA5wNHAWeOPHpEkDW+wsKiq+6rq+rb8JeB2YCWwDtjUpm0CTmrL64Dza+Qq4MAkhwAnAJuramd7mOFm4MSh+pYkPdJEzlkkWc3oKbVXAyuq6r429DlgRVteCdwz9rZ7W22u+u6fsSHJliRbduzYsbC/gCQtcYOHRZKnAB8EXldVXxwfq6oCaiE+p6rOraq1VbV2ZsZvfJWkhTRoWCR5IqOgeH9V/UMrf74dXqL93N7q24BDx96+qtXmqkuSJmTIq6ECnAfcXlV/OjZ0GTB7RdN64NKx+qntqqhjgAfb4arLgeOTLG8nto9vNUnShAz5BUY/DrwauCXJja32e8CbgYuSnA7czei7vQE+DLwI2Ap8GTgNRt/Kl+SNwLVt3tntm/okSRMyWFhU1SeAzDF83B7mF3DGHNvaCGxcuO4kSY+Fd3BLkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1DVYWCTZmGR7kk+N1Q5KsjnJne3n8lZPknck2Zrk5iTPHnvP+jb/ziTrh+pXkjS3Ifcs3gucuFvtTOCKqloDXNHWAV4IrGmvDcC7YRQuwFnAc4CjgbNmA0aSNDmDhUVVfRzYuVt5HbCpLW8CThqrn18jVwEHJjkEOAHYXFU7q2oXsJlHBpAkaWCTPmexoqrua8ufA1a05ZXAPWPz7m21ueqPkGRDki1JtuzYsWNhu5akJW5qJ7irqoBawO2dW1Vrq2rtzMzMQm1WksTkw+Lz7fAS7ef2Vt8GHDo2b1WrzVWXJE3QpMPiMmD2iqb1wKVj9VPbVVHHAA+2w1WXA8cnWd5ObB/fapKkCVo21IaT/D3wfODgJPcyuqrpzcBFSU4H7gZe0aZ/GHgRsBX4MnAaQFXtTPJG4No27+yq2v2kuSRpYIOFRVW9co6h4/Ywt4Az5tjORmDjArYmSXqMvINbktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUtdeERZITk9yRZGuSM6fdjyQtJXtFWCTZD/gL4IXAEcArkxwx3a4kaenYK8ICOBrYWlV3VdX/ABcA66bckyQtGcum3cA8rQTuGVu/F3jO+IQkG4ANbfWhJHdMqLel4GDgC9NuYjHIW9dPuwV9K/82Z52VhdjK98w1sLeERVdVnQucO+0+9kVJtlTV2mn3Ie3Ov83J2VsOQ20DDh1bX9VqkqQJ2FvC4lpgTZLDk+wPnAJcNuWeJGnJ2CsOQ1XVw0l+Fbgc2A/YWFW3TrmtpcTDe1qs/NuckFTVtHuQJC1ye8thKEnSFBkWkqQuw0KPWZLnJ3nutPvQ0pPkDUl+a9p9LEWGhf4/ng8YFtISYljoG5KcmuTmJDcleV+SlyS5OskNSf41yYokq4FfBn4jyY1JnjfltrWPS/L7Sf4jySeA72+1I5Nc1f5eL0myvNV/tNVuTPLHST411eb3IV4NJQCSPAO4BHhuVX0hyUFAAQ9UVSX5ReAHq+o3k7wBeKiq3jrFlrUEJDkKeC+jx/ssA64H/hI4Ffi1qroyydnAU6vqdS0cfqmqPpnkzcCLq+qZU2p/n7JX3GehiTgW+EBVfQGgqnYmeRZwYZJDgP2Bz0yzQS1JzwMuqaovAyS5DPgO4MCqurLN2QR8IMmBwAFV9clW/zvgxRPud5/lYSg9mncCf15VzwJeAzxpyv1ImhLDQrM+Arw8ydMB2mGop/HNZ3CNP271S8ABk21PS9THgZOSPDnJAcBLgP8Gdo2dL3s1cGVVPQB8KcnsE6lPmXi3+zAPQwmAqro1yTnAlUm+BtwAvIHR7v0uRmFyeJv+T8DFSdYxOm78b9PoWfu+qro+yYXATcB2Rs+Jg9F/Xv4yybcDdwGntfrpwF8n+TpwJfDghFveZ3mCW9I+I8lTquqhtnwmcEhVvXbKbe0T3LOQtC/56SSvZ/Rv293Az0+3nX2HexaSpC5PcEuSugwLSVKXYSFJ6jIspAWQ5KHO+OrH+pyiJO9NcvLj60xaGIaFJKnLsJAWUJKnJLkiyfVJbmk3Ls5aluT9SW5PcnG7oYwkRyW5Msl1SS5vz+KSFhXDQlpYXwF+pqqeDbwA+JMkaWPfD7yrqn4Q+CLwK0meyOgZXCdX1VHARuCcKfQtPSpvypMWVoA/SvKTwNeBlcCKNnZPVf17W/5b4NeBfwaeCWxumbIfcN9EO5bmwbCQFtbPATPAUVX1v0k+yzef1rv7HbDFKFxuraofm1yL0mPnYShpYT0N2N6C4gXA94yNHZZkNhR+FvgEcAcwM1tP8sT2RVTSomJYSAvr/cDaJLcw+ja3T4+N3QGckeR2YDnw7qr6H+Bk4C1JbgJuxO831yLks6EkSV3uWUiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK7/AxbCck6Gyhm2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Summarise label details in training data\n",
        "sns.countplot(x=df_train['label'])\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write the function to load the dataset."
      ],
      "metadata": {
        "id": "S3BggqPkMyxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ECiGPRnAA8SC"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "# ids - list of image ids\n",
        "# folder_path - path to image folder\n",
        "# dim - dimensions to resize images\n",
        "def load_images(ids, folder_path, dim):\n",
        "  images = []\n",
        "  for id in ids:\n",
        "    image_path = os.path.join(folder_path, f'{id}.jpg')\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Resize if necessary\n",
        "    if img.shape[0] != dim[1] or img.shape[1] != dim[0]:\n",
        "      img = cv2.resize(img, dim)\n",
        "    images.append(img)\n",
        "  return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESHUQVrcBbYE",
        "outputId": "9a2f2ab2-58ac-4c3f-84fa-08e34110f7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images loaded: 10000\n",
            "Number of testing images loaded: 1000\n"
          ]
        }
      ],
      "source": [
        "base_dim = (200, 200)\n",
        "\n",
        "# load train images\n",
        "train_image_folder = os.path.join(data_folder, 'train_images')\n",
        "train_images = load_images(df_train['id'], train_image_folder, base_dim)\n",
        "print(f'Number of training images loaded: {len(train_images)}')\n",
        "\n",
        "# load test images\n",
        "test_image_folder = os.path.join(data_folder, 'test_images')\n",
        "test_images = load_images(df_test['id'], test_image_folder, base_dim)\n",
        "print(f'Number of testing images loaded: {len(test_images)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts(normalize =True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuY3kFWx4dCM",
        "outputId": "b3825347-cafc-43e1-9fb4-70cf825841f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dog    0.5011\n",
              "cat    0.4989\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"label\"] = df_train[\"label\"].map({'cat':1 ,'dog':0})\n",
        "df_train"
      ],
      "metadata": {
        "id": "GCM4d0nu4c0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "df8cc697-3bf6-4e0c-9065-e7de3394f5f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  label\n",
              "0         1      1\n",
              "1         2      0\n",
              "2         3      1\n",
              "3         4      1\n",
              "4         5      1\n",
              "...     ...    ...\n",
              "9995   9996      1\n",
              "9996   9997      0\n",
              "9997   9998      1\n",
              "9998   9999      0\n",
              "9999  10000      0\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5c31bf3-456c-4344-9058-a655306e4eea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5c31bf3-456c-4344-9058-a655306e4eea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5c31bf3-456c-4344-9058-a655306e4eea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5c31bf3-456c-4344-9058-a655306e4eea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuyAqDKuD9o_"
      },
      "source": [
        "#Feature extraction and model generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s-4y8ur4Co-N"
      },
      "outputs": [],
      "source": [
        "# method to plot confusion matrix\n",
        "def plot_confusion_matrix(matrix):\n",
        "    plt.clf()\n",
        "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Set2_r)\n",
        "    classNames = ['0', '1']\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    tick_marks = np.arange(len(classNames))\n",
        "    plt.xticks(tick_marks, classNames)\n",
        "    plt.yticks(tick_marks, classNames)\n",
        "    s = [['TN','FP'], ['FN', 'TP']]\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j,i, str(s[i][j])+\" = \"+str(matrix[i][j]))\n",
        "    plt.show()\n",
        "\n",
        "# method to calculate evaluation results\n",
        "def evaluate(actuals, predictions):\n",
        "  accuracy = metrics.accuracy_score(actuals, predictions)\n",
        "  confusion_matrix = metrics.confusion_matrix(actuals, predictions, labels=[0, 1])\n",
        "  return accuracy, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIMiiy8RE7a3"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fw6BcrifLaoW"
      },
      "outputs": [],
      "source": [
        "def build_svm_model(X_train, X_val, y_train, y_val):\n",
        "  # build model\n",
        "  clf = svm.SVC(kernel='linear', random_state=RANDOM_SEED) \n",
        "  clf.fit(X_train, y_train)\n",
        "  return clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMYPuFbUFIrs"
      },
      "source": [
        "# Model M1\n",
        "\n",
        "*   Preprocessing - gray scaling\n",
        "*   Features - image vector\n",
        "*   Algorithm - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HuDDp_z6KCno"
      },
      "outputs": [],
      "source": [
        "# method to get image features\n",
        "#def get_features_m1(images):\n",
        " # features_list = []\n",
        "  #for img in images:\n",
        "    # image preprocessing\n",
        "   # img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # vectorise/ feature extraction\n",
        "   # features = img_grayscaled.flatten()\n",
        "\n",
        "   # features_list.append(features)\n",
        "\n",
        " # features_list = np.array(features_list)\n",
        " # return features_list\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGBfaU-GHId"
      },
      "source": [
        "#Train and Validate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7ecDaWZ3LfXj"
      },
      "outputs": [],
      "source": [
        "# feature extraction\n",
        "#features_train = get_features_m1(train_images)\n",
        "#print(features_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dc8J2Yf_MLt4"
      },
      "outputs": [],
      "source": [
        "# data split for train and validation\n",
        "#X_train, X_val, y_train, y_val = train_test_split(features_train, df_train['label'], test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# train model\n",
        "#m1 = build_svm_model(X_train, X_val, y_train, y_val)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1sm2uSseNilZ"
      },
      "outputs": [],
      "source": [
        "# make predictions on validation data\n",
        "#y_pred = m1.predict(X_val)\n",
        "\n",
        "# evaluate model\n",
        "#accuracy, confusion_matrix = evaluate(y_val, y_pred)\n",
        "#print(f'Accuracy: {accuracy}')\n",
        "#plot_confusion_matrix(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_val"
      ],
      "metadata": {
        "id": "yBNmW9a34MCO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MyhD2g7f2xuh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjjVttOT7U-B"
      },
      "source": [
        "# Make predictions on test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k4bBrwE9O9UW"
      },
      "outputs": [],
      "source": [
        "# feature extraction - test data\n",
        "#features_test = get_features_m1(test_images)\n",
        "#print(features_test.shape)\n",
        "\n",
        "# get model predictions\n",
        "#predictions = m1.predict(features_test)\n",
        "#print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S9a7ZlMIt2P"
      },
      "source": [
        "# Model M2\n",
        "\n",
        "*   Preprocessing - gray scaling, smoothing\n",
        "*   Features - image vector \n",
        "*   Algorithm - SVM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DcnewcTSnb61"
      },
      "outputs": [],
      "source": [
        "seed(RANDOM_SEED)\n",
        "sample_images = []\n",
        "\n",
        "# pick random sample of images\n",
        "#for i in range(5):\n",
        " # value = randint(0, len(train_images)-1)\n",
        " # print(f'Image Id: {value}')\n",
        " # sample_images.append(train_images[value])\n",
        "\n",
        "# apply preprocessing and show output images\n",
        "#for img in sample_images:\n",
        " # img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        " # plt.imshow(cv2.cvtColor(img_grayscaled, cv2.COLOR_BGR2RGB))\n",
        " # plt.show()\n",
        "\n",
        "  #img_blurred = cv2.GaussianBlur(img_grayscaled,(3,3), 2)\n",
        " # plt.imshow(cv2.cvtColor(img_blurred, cv2.COLOR_BGR2RGB))\n",
        " # plt.show()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qbKJ2aziHoOC"
      },
      "outputs": [],
      "source": [
        "# method to get image features\n",
        "#def get_features_m2(images):\n",
        " # features_list = []\n",
        " # for img in images:\n",
        "    # image preprocessing\n",
        "   # img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "   # img_blurred = cv2.GaussianBlur(img_grayscaled,(3,3), 2)\n",
        "\n",
        "    # vectorise/ feature extraction\n",
        "    #features = img_blurred.flatten()\n",
        "\n",
        "   # features_list.append(features)\n",
        "\n",
        " # features_list = np.array(features_list)\n",
        " # return features_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yssrPc6FLf9X"
      },
      "source": [
        "#Train and validate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "56ntU5KMLddC"
      },
      "outputs": [],
      "source": [
        "#features_train = get_features_m2(train_images)\n",
        "#print(features_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x1oVKzOSLtBH"
      },
      "outputs": [],
      "source": [
        "# data split for train and validation\n",
        "#X_train, X_val, y_train, y_val = train_test_split(features_train, df_train['label'], test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# train model\n",
        "#m2 = build_svm_model(X_train, X_val, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dPHknV36L0Zg"
      },
      "outputs": [],
      "source": [
        "# make predictions on validation data\n",
        "#y_pred = m2.predict(X_val)\n",
        "\n",
        "# evaluate model\n",
        "#accuracy, confusion_matrix = evaluate(y_val, y_pred)\n",
        "#print(f'Accuracy: {accuracy}')\n",
        "#plot_confusion_matrix(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi3bhO0mMWuN"
      },
      "source": [
        "#Make predictions on test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NVu6hlcxMUOa"
      },
      "outputs": [],
      "source": [
        "# feature extraction - test data\n",
        "#features_test = get_features_m2(test_images)\n",
        "#print(features_test.shape)\n",
        "\n",
        "# get model predictions\n",
        "#predictions = m2.predict(features_test)\n",
        "\n",
        "#print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz4cTtrwMnNO"
      },
      "source": [
        "#Model M3\n",
        "\n",
        "\n",
        "*   Preprocessing - gray scaling\n",
        "*   Features -edge map to vector\n",
        "*   Algorithm - SVM\n",
        "\n",
        "Canny edge detection algorithm has been used here.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qxqUvFTRMh3w"
      },
      "outputs": [],
      "source": [
        "# method to get image features\n",
        "#def get_features_m3(images):\n",
        "  #features_list = []\n",
        "  #for img in images:\n",
        "    # image preprocessing\n",
        "   # img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # feature extraction\n",
        "    #edges_canny = cv2.Canny(img_grayscaled, 100, 200) \n",
        "    #features = edges_canny.flatten()\n",
        "\n",
        "    #features_list.append(features)\n",
        "\n",
        "  #features_list = np.array(features_list)\n",
        "  #return features_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OxLwRJFN4tz"
      },
      "source": [
        "#Train and validate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XVZqJ83HNRrO"
      },
      "outputs": [],
      "source": [
        "# feature extraction\n",
        "#features_train = get_features_m3(train_images)\n",
        "#print(features_train.shape)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RlyE0uQTONbl"
      },
      "outputs": [],
      "source": [
        "# data split for train and validation\n",
        "#X_train, X_val, y_train, y_val = train_test_split(features_train, df_train['label'], test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# train model\n",
        "#m3 = build_svm_model(X_train, X_val, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1_femVXPOUl9"
      },
      "outputs": [],
      "source": [
        "# make predictions on validation data\n",
        "#y_pred = m3.predict(X_val)\n",
        "\n",
        "# evaluate model\n",
        "#accuracy, confusion_matrix = evaluate(y_val, y_pred)\n",
        "#print(f'Accuracy: {accuracy}')\n",
        "#plot_confusion_matrix(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEdUFXq5ObMq"
      },
      "source": [
        "#Make predictions on test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mMGTZVtvOXQG"
      },
      "outputs": [],
      "source": [
        "# feature extraction - test data\n",
        "#features_test = get_features_m3(test_images)\n",
        "#print(features_test.shape)\n",
        "\n",
        "# get model predictions\n",
        "#predictions = m3.predict(features_test)\n",
        "\n",
        "#print(predictions)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re3K4PRROrYl"
      },
      "source": [
        "#Model M4\n",
        "\n",
        "\n",
        "*   Preprocessing - gray scaling\n",
        "*   Features HOG features\n",
        "*   Algorithm - SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wfLuEwhaOnee"
      },
      "outputs": [],
      "source": [
        "# method to get image features\n",
        "def get_features_m4(images):\n",
        "  features_list = []\n",
        "  for img in images:\n",
        "    # image preprocessing\n",
        "    img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Resize image if necessary\n",
        "    img_resized = cv2.resize(img_grayscaled, (64, 128))\n",
        "\n",
        "    # feature extraction\n",
        "    features, hog_image = hog(img_resized, orientations=9, pixels_per_cell=(8, 8), \n",
        "                    cells_per_block=(2, 2), visualize=True)\n",
        "\n",
        "    features_list.append(features)\n",
        "\n",
        "  features_list = np.array(features_list)\n",
        "  return features_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guKwsSHmPimw"
      },
      "source": [
        "#Train and Validate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9Zk_LsdMPKSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f21b582-f9a3-4663-e04c-80b701fe38c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 3780)\n"
          ]
        }
      ],
      "source": [
        "# feature extraction\n",
        "features_train = get_features_m4(train_images)\n",
        "print(features_train.shape)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "AB_b4NyRPsY7"
      },
      "outputs": [],
      "source": [
        "# data split for train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_train, df_train['label'], test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# train model\n",
        "m4 = build_svm_model(X_train, X_val, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "L79eEtQdPu1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "647b6c23-8e2d-41e5-9a61-8ddefdbbf04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6693333333333333\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# make predictions on validation data\n",
        "y_pred = m4.predict(X_val)\n",
        "\n",
        "# evaluate model\n",
        "accuracy, confusion_matrix = evaluate(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "plot_confusion_matrix(confusion_matrix)\n",
        "     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCHEtnJlP0Il"
      },
      "source": [
        "#Make predictions on test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "__gvfGKlPydA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48b382e-f0b3-4bbd-cdaf-bafdb29348db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3780)\n",
            "['cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'dog']\n"
          ]
        }
      ],
      "source": [
        "#feature extraction - test data\n",
        "features_test = get_features_m4(test_images)\n",
        "print(features_test.shape)\n",
        "\n",
        "# get model predictions\n",
        "predictions = m4.predict(features_test)\n",
        "\n",
        "\n",
        "# # Define a dictionary to map 0 and 1 to cat and dog\n",
        "label_map = {0: 'cat', 1: 'dog'}\n",
        "\n",
        "# # Convert predictions from 0 and 1 to cat and dog\n",
        "predictions = [label_map[prediction] for prediction in predictions]\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_test['prediction'] = predictions\n",
        "\n",
        "data = []\n",
        "for index, row in df_test.iterrows():\n",
        "    data.append({'id': row['id'], 'prediction': row['prediction']})\n",
        "\n",
        "print(data[0:5])\n",
        "\n",
        "submission_file_path = \"submission.json\"\n",
        "with open(submission_file_path, 'w') as fp:\n",
        "    fp.write('\\n'.join(json.dumps(i) for i in data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_YSvSQwDxIh",
        "outputId": "8b26c75c-18e4-4601-9a2f-512c3f6fd2e8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 1, 'prediction': 'cat'}, {'id': 2, 'prediction': 'dog'}, {'id': 3, 'prediction': 'dog'}, {'id': 4, 'prediction': 'dog'}, {'id': 5, 'prediction': 'cat'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQusBOtUKVw"
      },
      "source": [
        "#Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g0YWd2jVN7g"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-v1RUd_jnY0"
      },
      "source": [
        "#Model M5\n",
        "\n",
        "Lets try to combine features.\n",
        "\n",
        "*   Preprocessing - gray scaling\n",
        "*   Features - image vector + edge map vector\n",
        "*   Algorithm - SVM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGj1dDe7P_WU"
      },
      "outputs": [],
      "source": [
        "# method to get image features\n",
        "def get_features_m5(images):\n",
        "  features_list = []\n",
        "  for img in images:\n",
        "    # image preprocessing\n",
        "    img_grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  \n",
        "    # feature extraction\n",
        "    edges_canny = cv2.Canny(img_grayscaled, 100, 200) \n",
        "    features1 = img_grayscaled.flatten()\n",
        "    features2 = edges_canny.flatten()\n",
        "    features = np.hstack((features1, features2))\n",
        "\n",
        "    features_list.append(features)\n",
        "\n",
        "  features_list = np.array(features_list)\n",
        "  return features_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zIdLPU3k9Ff"
      },
      "source": [
        "Train and validate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9N3r2uIUJy7"
      },
      "outputs": [],
      "source": [
        "# feature extraction\n",
        "features_train = get_features_m5(train_images)\n",
        "print(features_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SH8tm8DlEZQ"
      },
      "outputs": [],
      "source": [
        "# data split for train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(features_train, df_train['label'], test_size=0.3, random_state=RANDOM_SEED)\n",
        "\n",
        "# train model\n",
        "m5 = build_svm_model(X_train, X_val, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUgqU_u0lGrJ"
      },
      "outputs": [],
      "source": [
        "# make predictions on validation data\n",
        "y_pred = m5.predict(X_val)\n",
        "\n",
        "# evaluate model\n",
        "accuracy, confusion_matrix = evaluate(y_val, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "plot_confusion_matrix(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA9k4H3elVMO"
      },
      "source": [
        "#Make predictions on test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju4WO-ktlKLh"
      },
      "outputs": [],
      "source": [
        "# feature extraction - test data\n",
        "features_test = get_features_m5(test_images)\n",
        "print(features_test.shape)\n",
        "\n",
        "# get model predictions\n",
        "predictions = m5.predict(features_test)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7yaQFeSle-V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CnyZR7d21IHAfJhQpTX5ebYowuoFGP7A",
      "authorship_tag": "ABX9TyP6xDHaqp8w08aPwMhBYMWr",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}